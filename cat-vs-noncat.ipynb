{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "print('here we start our logistic regression project \\n')\n",
    "print('Problem Statement: You are given a dataset (\"data.h5\") containing: - a training set of m_train images labeled as cat (y=1) or non-cat (y=0) - a test set of m_test images labeled as cat or non-cat - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px). You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat. \\n')\n",
    "\n",
    "def load_dataset():\n",
    "  print('loading the dataset. we run a method instead of including a module named load_dataset that is required in the imports in the course module. \\n')\n",
    "  # file_data = scipy.io.loadmat('dataset.mat')\n",
    "  train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "  test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "  classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "  \n",
    "  print('Each line of your train_set_x_orig and test_set_x_orig is an array representing an image \\n')\n",
    "\n",
    "  train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "  test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "  return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "\n",
    "# check an example of a picture that exists in the dataset loaded\n",
    "print('the following is the image number 7 of the dataset. \\n')\n",
    "index = 7\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture. \\n\")\n",
    "\n",
    "print('we loaded the following data: \\n')\n",
    "print(train_set_x_orig.shape)\n",
    "print('\\n')\n",
    "\n",
    "# exercise \n",
    "\n",
    "print('Exercise: Find the values for: - m_train (number of training examples) - m_test (number of test examples) - num_px (= height = width of a training image) Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0]. \\n') \n",
    "\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape) + str('\\n'))\n",
    "\n",
    "# exercise 2\n",
    "\n",
    "print('Exercise: Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px num_px 3, 1). \\n')\n",
    "\n",
    "# A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b*c*d, a) is to use:\n",
    "# X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n",
    "# train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "# test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "train_x_product = train_set_x_orig.shape[1] * train_set_x_orig.shape[2] * train_set_x_orig.shape[3]\n",
    "test_x_product = test_set_x_orig.shape[1] * test_set_x_orig.shape[2] * test_set_x_orig.shape[3]\n",
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_x_product, train_set_x_orig.shape[0] )\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_x_product, test_set_x_orig.shape[0])\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print ('sanity check after reshaping: ' + str(train_set_x_flatten[0:5,0]) + '\\n')\n",
    "\n",
    "print('To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255. One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel). \\n')\n",
    "\n",
    "# lets standardize the dataset\n",
    "\n",
    "train_set_x = train_set_x_flatten/255\n",
    "test_set_x = test_set_x_flatten/255\n",
    "\n",
    "# **What you need to remember:**\n",
    "# Common steps for pre-processing a new dataset are:\n",
    "# Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, ...)\n",
    "# Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)\n",
    "# \"Standardize\" the data\n",
    "\n",
    "print(\"let's now determine how to create a neural network that help us solve the problem of identifying cat images\\n\")\n",
    "print(\"the following is a set of steps we will use to solve the problem\\n\")\n",
    "print(\"1. initialize the parameters of the model.\\n\")\n",
    "print(\"2. learn the parameters for the model by minimizing the cost function.\\n\")\n",
    "print(\"3. use the learned parameters to make predictions over the test set.\\n\")\n",
    "print(\"4. analyse the results and conclude.\\n\")\n",
    "\n",
    "# building the parts of our algorithm: \n",
    "# 1. define the model structure\n",
    "# 2. initialize the parameters for the model\n",
    "# 3. loop: calculate current loss (forward propagation), calculate current gradient (backward propagation), update the parameters (gradient descent)\n",
    "# build each step separately and calculate a method called model where everything is integrated\n",
    "\n",
    "# exercise 3 \n",
    "print(\"implement sigmoid function to make predictions. use np.exp()\")\n",
    "\n",
    "# GRADED FUNCTION: sigmoid \n",
    "\n",
    "print(\"we will start by defining the model structure and the helper methods to execute calculations base in our activation function, and the initialization step which requires an initialize function.\\n\")\n",
    "print(\"1. define the model structure.\\n\")\n",
    "\n",
    "def sigmoid(z):\n",
    "  \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "  sig = 1/(1 + np.exp(-z))\n",
    "  \n",
    "  return sig\n",
    "\n",
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0, 2]))))\n",
    "print (\"\\nExercise: Implement parameter initialization in the cell below. You have to initialize w as a vector of zeros. If you don't know what numpy function to use, look up np.zeros() in the Numpy library's documentation.\\n\")\n",
    "\n",
    "# GRADED FUNCTION: initialize with zeros\n",
    "\n",
    "print(\"2. initialize the model parameter (attributes).\\n\")\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "  \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "  \n",
    "  w = np.zeros((dim, 1))\n",
    "  b = 0\n",
    "  \n",
    "  assert(w.shape == (dim, 1))\n",
    "  assert(isinstance(b, float) or isinstance(b, int))\n",
    "  \n",
    "  return w, b\n",
    "\n",
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print(\"w = \" + str(w) + \"\\n\")\n",
    "print(\"b = \" + str(b) + \"\\n\")\n",
    "\n",
    "print(\"3. calculate current loss, current gradient and update the parameters.\\n\")\n",
    "print(\"Exercise: implement a function => propagate() that computes the cost function and its gradients.\\n\")\n",
    "\n",
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "# forward propagation\n",
    "# - you get X (dataset)\n",
    "# - you compute the activation function A = sigmoid(wT.X + b) = (a(1), a(2), a(3)...a(m))\n",
    "# - you calculate the cost function J = -1/m . summation(1 to m) (y(i). log(a(i)) + (1 - y(i). log(1 - a(i))))\n",
    "\n",
    "# formulas to use:\n",
    "# dj/dw = 1/m . (X(A - Y)T) => a minus y transpose\n",
    "# dj/db = 1/m . summation(1 to m) (a(i) -y(i))\n",
    "\n",
    "def propagate(weights, bias, data, labels):\n",
    "  \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w(weights) -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b(bias) -- bias, a scalar\n",
    "    X(data) -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y(labels) -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "  data_shape = data.shape[1]\n",
    "  \n",
    "  # FORWARD PROPAGATION (FROM data TO cost)\n",
    "  activations = sigmoid(np.dot(weights.T, data) + bias)\n",
    "  cost = np.sum((- np.log(activations) * labels + (- np.log(1 - activations)) * (1 - labels)))/ data_shape\n",
    "  # END FORWARD PROPAGATION  \n",
    "  \n",
    "  # BACKWARD PROPAGATION (TO FIND gradients)\n",
    "  dw = (np.dot(data, (activations-labels).T))/data_shape\n",
    "  db = (np.sum(activations-labels))/data_shape\n",
    "  # END BACKWARD PROPAGATIONS\n",
    "  \n",
    "  assert(dw.shape == weights.shape)\n",
    "  assert(db.dtype == float)\n",
    "  cost = np.squeeze(cost)\n",
    "  assert(cost.shape == ())\n",
    "  \n",
    "  gradients = {\"dw\": dw, \n",
    "               \"db\": db}\n",
    "  \n",
    "  return gradients, cost\n",
    "\n",
    "weights, bias, data, labels = (np.array([[1.], [2.]]), \n",
    "                               2., \n",
    "                               np.array([[1., 2., -1.],[3., 4., -3.2]]), \n",
    "                               np.array([[1, 0, 1]]))\n",
    "grads, cost = propagate(weights, bias, data, labels)\n",
    "print (\"calculate the propagation function with weights = 1. and 2. , bias = 2. , data = [1.,2.,-1.],[3.,4.,-3.2] and  labels = [1, 0, 1]. \\n\")\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e350bd9a7f69ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
